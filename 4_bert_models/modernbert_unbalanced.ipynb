{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TPBMCPlU64zt"
   },
   "source": [
    "# ModernBERT with unbalanced dataset\n",
    "\n",
    "Notebook by: [Juliana Gómez Consuegra](https://www.linkedin.com/in/julianagomezconsuegra/)\n",
    "\n",
    "- Documentation: https://huggingface.co/docs/transformers/en/model_doc/modernbert\n",
    "\n",
    "Notes:\n",
    "\n",
    "- The pre-trained ModernBERT-base model doesn't include a classification layer, so when you create a ModernBertForSequenceClassification model, it adds a new classification layer on top of the base model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10105,
     "status": "ok",
     "timestamp": 1738204032983,
     "user": {
      "displayName": "Juliana Consuegra",
      "userId": "10397928924368773142"
     },
     "user_tz": 300
    },
    "id": "Iu8oRuoqBxhV",
    "outputId": "87f1df47-62f1-4aa7-adb1-9b6e4b73b8c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fsspec==2024.10.0\n",
      "  Downloading fsspec-2024.10.0-py3-none-any.whl.metadata (11 kB)\n",
      "Downloading fsspec-2024.10.0-py3-none-any.whl (179 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.6/179.6 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: fsspec\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2024.9.0\n",
      "    Uninstalling fsspec-2024.9.0:\n",
      "      Successfully uninstalled fsspec-2024.9.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "datasets 3.2.0 requires fsspec[http]<=2024.9.0,>=2023.1.0, but you have fsspec 2024.10.0 which is incompatible.\n",
      "torch 2.5.1+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
      "torch 2.5.1+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
      "torch 2.5.1+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
      "torch 2.5.1+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
      "torch 2.5.1+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
      "torch 2.5.1+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
      "torch 2.5.1+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
      "torch 2.5.1+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
      "torch 2.5.1+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
      "torch 2.5.1+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed fsspec-2024.10.0\n"
     ]
    }
   ],
   "source": [
    "#upgrade fsspec to solve dependency issuse\n",
    "!pip install -U fsspec==2024.10.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18747,
     "status": "ok",
     "timestamp": 1738204051728,
     "user": {
      "displayName": "Juliana Consuegra",
      "userId": "10397928924368773142"
     },
     "user_tz": 300
    },
    "id": "qwBw9nst64Oz",
    "outputId": "acafa059-c84b-40ac-9368-4b8f9cd83c16"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torch 2.5.1+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
      "torch 2.5.1+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
      "torch 2.5.1+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
      "torch 2.5.1+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
      "torch 2.5.1+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
      "torch 2.5.1+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
      "torch 2.5.1+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
      "torch 2.5.1+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
      "torch 2.5.1+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
      "torch 2.5.1+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\n",
      "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -q datasets\n",
    "!pip install -q codecarbon\n",
    "!pip install -q -U transformers>=4.48.0\n",
    "# !pip install -q flash- #not available for T4: RuntimeError: FlashAttention only supports Ampere GPUs or newer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EQ8INiRj9bZv"
   },
   "outputs": [],
   "source": [
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xMUp1bE07dRY"
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "#standard libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "#emissions tracking\n",
    "from codecarbon import EmissionsTracker\n",
    "\n",
    "\n",
    "# accuracy and model\n",
    "from datasets import load_dataset, DatasetDict\n",
    "import torch\n",
    "from functools import partial\n",
    "import gc\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, ModernBertForSequenceClassification,TrainingArguments, Trainer, TrainerCallback, DataCollatorWithPadding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 41044,
     "status": "ok",
     "timestamp": 1738204113294,
     "user": {
      "displayName": "Juliana Consuegra",
      "userId": "10397928924368773142"
     },
     "user_tz": 300
    },
    "id": "Rhr4WG2f7fvS",
    "outputId": "08e0d4dd-94c8-42d1-ad41-c8844ab0528b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# dataset\n",
    "dataset = load_dataset(\"quotaclimat/frugalaichallenge-text-train\")\n",
    "\n",
    "# Define the label mapping\n",
    "LABEL_MAPPING = {\n",
    "    \"0_not_relevant\": 0,\n",
    "    \"1_not_happening\": 1,\n",
    "    \"2_not_human\": 2,\n",
    "    \"3_not_bad\": 3,\n",
    "    \"4_solutions_harmful_unnecessary\": 4,\n",
    "    \"5_science_unreliable\": 5,\n",
    "    \"6_proponents_biased\": 6,\n",
    "    \"7_fossil_fuels_needed\": 7\n",
    "}\n",
    "\n",
    "# Convert string labels to integers\n",
    "dataset = dataset.map(lambda x: {\"label\": LABEL_MAPPING[x[\"label\"]]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EIoARAuk__WB"
   },
   "source": [
    "# Fine-tuning ModernBERT on the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T6NDeyJGD0RZ"
   },
   "outputs": [],
   "source": [
    "# tokenizer\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"answerdotai/ModernBERT-base\")\n",
    "# model = ModernBertForSequenceClassification.from_pretrained(\"answerdotai/ModernBERT-base\", num_labels=len(LABEL_MAPPING))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7131,
     "status": "ok",
     "timestamp": 1738204120423,
     "user": {
      "displayName": "Juliana Consuegra",
      "userId": "10397928924368773142"
     },
     "user_tz": 300
    },
    "id": "Gnmfnj7H-gSi",
    "outputId": "f7c3aaae-6675-4be6-aea4-56099cc6289e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load tokenizer\n",
    "model_name = \"answerdotai/ModernBERT-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Load model with alternative attention implementation\n",
    "model = ModernBertForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=len(LABEL_MAPPING),\n",
    "    attn_implementation=\"sdpa\"  #SDPA (Scaled Dot Product Attention)\n",
    ").to('cuda')\n",
    "\n",
    "model.gradient_checkpointing_enable()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 174,
     "status": "ok",
     "timestamp": 1738204127862,
     "user": {
      "displayName": "Juliana Consuegra",
      "userId": "10397928924368773142"
     },
     "user_tz": 300
    },
    "id": "g_Og6CVWzIza",
    "outputId": "9e37e255-8798-4419-ce5b-33ed5eed8e20"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.embeddings.tok_embeddings.weight: True\n",
      "model.embeddings.norm.weight: True\n",
      "Layer 0: False\n",
      "Layer 0: False\n",
      "Layer 0: False\n",
      "Layer 0: False\n",
      "Layer 0: False\n",
      "Layer 1: False\n",
      "Layer 1: False\n",
      "Layer 1: False\n",
      "Layer 1: False\n",
      "Layer 1: False\n",
      "Layer 1: False\n",
      "Layer 2: False\n",
      "Layer 2: False\n",
      "Layer 2: False\n",
      "Layer 2: False\n",
      "Layer 2: False\n",
      "Layer 2: False\n",
      "Layer 3: False\n",
      "Layer 3: False\n",
      "Layer 3: False\n",
      "Layer 3: False\n",
      "Layer 3: False\n",
      "Layer 3: False\n",
      "Layer 4: False\n",
      "Layer 4: False\n",
      "Layer 4: False\n",
      "Layer 4: False\n",
      "Layer 4: False\n",
      "Layer 4: False\n",
      "Layer 5: False\n",
      "Layer 5: False\n",
      "Layer 5: False\n",
      "Layer 5: False\n",
      "Layer 5: False\n",
      "Layer 5: False\n",
      "Layer 6: False\n",
      "Layer 6: False\n",
      "Layer 6: False\n",
      "Layer 6: False\n",
      "Layer 6: False\n",
      "Layer 6: False\n",
      "Layer 7: False\n",
      "Layer 7: False\n",
      "Layer 7: False\n",
      "Layer 7: False\n",
      "Layer 7: False\n",
      "Layer 7: False\n",
      "Layer 8: False\n",
      "Layer 8: False\n",
      "Layer 8: False\n",
      "Layer 8: False\n",
      "Layer 8: False\n",
      "Layer 8: False\n",
      "Layer 9: False\n",
      "Layer 9: False\n",
      "Layer 9: False\n",
      "Layer 9: False\n",
      "Layer 9: False\n",
      "Layer 9: False\n",
      "Layer 10: False\n",
      "Layer 10: False\n",
      "Layer 10: False\n",
      "Layer 10: False\n",
      "Layer 10: False\n",
      "Layer 10: False\n",
      "Layer 11: False\n",
      "Layer 11: False\n",
      "Layer 11: False\n",
      "Layer 11: False\n",
      "Layer 11: False\n",
      "Layer 11: False\n",
      "Layer 12: False\n",
      "Layer 12: False\n",
      "Layer 12: False\n",
      "Layer 12: False\n",
      "Layer 12: False\n",
      "Layer 12: False\n",
      "Layer 13: False\n",
      "Layer 13: False\n",
      "Layer 13: False\n",
      "Layer 13: False\n",
      "Layer 13: False\n",
      "Layer 13: False\n",
      "Layer 14: False\n",
      "Layer 14: False\n",
      "Layer 14: False\n",
      "Layer 14: False\n",
      "Layer 14: False\n",
      "Layer 14: False\n",
      "Layer 15: False\n",
      "Layer 15: False\n",
      "Layer 15: False\n",
      "Layer 15: False\n",
      "Layer 15: False\n",
      "Layer 15: False\n",
      "Layer 16: False\n",
      "Layer 16: False\n",
      "Layer 16: False\n",
      "Layer 16: False\n",
      "Layer 16: False\n",
      "Layer 16: False\n",
      "Layer 17: False\n",
      "Layer 17: False\n",
      "Layer 17: False\n",
      "Layer 17: False\n",
      "Layer 17: False\n",
      "Layer 17: False\n",
      "Layer 18: False\n",
      "Layer 18: False\n",
      "Layer 18: False\n",
      "Layer 18: False\n",
      "Layer 18: False\n",
      "Layer 18: False\n",
      "Layer 19: False\n",
      "Layer 19: False\n",
      "Layer 19: False\n",
      "Layer 19: False\n",
      "Layer 19: False\n",
      "Layer 19: False\n",
      "Layer 20: False\n",
      "Layer 20: False\n",
      "Layer 20: False\n",
      "Layer 20: False\n",
      "Layer 20: False\n",
      "Layer 20: False\n",
      "Layer 21: True\n",
      "Layer 21: True\n",
      "Layer 21: True\n",
      "Layer 21: True\n",
      "Layer 21: True\n",
      "Layer 21: True\n",
      "model.final_norm.weight: True\n",
      "head.dense.weight: True\n",
      "head.norm.weight: True\n",
      "classifier.weight: True\n",
      "classifier.bias: True\n"
     ]
    }
   ],
   "source": [
    "# Freeze all layers except the last one\n",
    "for name, param in model.named_parameters():\n",
    "    if 'layers.' in name:\n",
    "        layer_num = int(name.split('.')[2])\n",
    "        if layer_num < 21:\n",
    "            param.requires_grad = False\n",
    "\n",
    "# Verify the freezing\n",
    "for name, param in model.named_parameters():\n",
    "    if 'layers.' in name:\n",
    "        layer_num = int(name.split('.')[2])\n",
    "        print(f\"Layer {layer_num}: {param.requires_grad}\")\n",
    "    else:\n",
    "        print(f\"{name}: {param.requires_grad}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zhLQROWb0Rim"
   },
   "outputs": [],
   "source": [
    "# see all layers\n",
    "# for name, param in model.named_parameters():\n",
    "#     print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tD6xahHlB4hY"
   },
   "source": [
    "## Split the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fhdrRdxjAFoJ"
   },
   "outputs": [],
   "source": [
    "def split_dataset(dataset, train_size=0.8, validation_size=0.1):\n",
    "    train_test_split = dataset['train'].train_test_split(test_size=1-train_size)\n",
    "    test_validation_split = train_test_split['test'].train_test_split(test_size=validation_size/(1-train_size))\n",
    "\n",
    "    dataset_dict = DatasetDict({\n",
    "        'train': train_test_split['train'],\n",
    "        'validation': test_validation_split['train'],\n",
    "        'test': test_validation_split['test']\n",
    "    })\n",
    "    return dataset_dict\n",
    "\n",
    "# Split the dataset\n",
    "dataset_splits = split_dataset(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D7IiI4PIB8Q3"
   },
   "source": [
    "### Tokenize the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 113,
     "referenced_widgets": [
      "0aa0953a0f974d1c91c61df90ced095a",
      "17bc325db5c5429ba34d0c32a707b2ec",
      "0d1c83c021c440af870a57809f3389e4",
      "295f3aa9490f49a09c30bd26f2df741f",
      "f23b7ffea8da4e7b8763cd9a32e8382b",
      "52c46c1088cd4a7daf5bcc7e94e7d087",
      "99cd9cd2ea4d4420b6b390303451e3dc",
      "a2f7717732bc42a797cea85bab375e6a",
      "e069534cc6f048cdb159b66167ee36d7",
      "66837dd64b3b45f1a5c58c8f4242ea40",
      "239ad12bdb0f433fb031fe2ce9679f3d",
      "884386a7232642b4be151749c69aefd1",
      "5196022684394923bfacd25d564d6fe4",
      "f3695012b5d5422fab1da2a8f7b2858b",
      "469c81a3f45c4803b4513eaee2693530",
      "0e93444e5a834ad78ccd6a1fdfa23b87",
      "01dd6d1a4053475da853c00463f02b35",
      "2052a53d024a42cf833cc9b0636176f2",
      "c179fefab74344368371b6457d36e7cf",
      "04f3d68881fd42edb13138b3164e723e",
      "59cd769513bd4c118c04d7cfc264a4a3",
      "d9a9cafcd88442c2a413d273b20dfe3e",
      "137e9dc3bc22481286d2b81ba0df6541",
      "84bbb54169dc4fe8b0c45b6d0597b088",
      "e7490ad417a64e8aaa969eeb989275b8",
      "f69828d20aa14305b2814dca42eddb23",
      "98615a5d1223470c9888676dd66f8ba7",
      "efba345573b54dca83bd88ce3c688358",
      "3d5fb52ef5ac42b3b9a908ce692e09e6",
      "7f5006b22c73431ca209452cbf70ac28",
      "f1a00a892b534f37b6f38bcd0c262434",
      "7e178350d50b4955810ba3e2d9733f51",
      "6a50d6b1564a4ac8ad711893d1d0ba32"
     ]
    },
    "executionInfo": {
     "elapsed": 30429,
     "status": "ok",
     "timestamp": 1738204167043,
     "user": {
      "displayName": "Juliana Consuegra",
      "userId": "10397928924368773142"
     },
     "user_tz": 300
    },
    "id": "BqxUb1SKCBw8",
    "outputId": "618fb397-c0be-4e8b-dc4d-055ecf5f7998"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0aa0953a0f974d1c91c61df90ced095a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3897 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "884386a7232642b4be151749c69aefd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/487 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "137e9dc3bc22481286d2b81ba0df6541",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/488 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['quote'], padding=\"max_length\", truncation=True)\n",
    "\n",
    "tokenized_datasets = dataset_splits.map(tokenize_function, batched=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PiibF3JkCHm5"
   },
   "source": [
    "### Set up hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V1KSfU3k5cKR"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 205,
     "status": "ok",
     "timestamp": 1738204338504,
     "user": {
      "displayName": "Juliana Consuegra",
      "userId": "10397928924368773142"
     },
     "user_tz": 300
    },
    "id": "ZhDBPxEuCLlz",
    "outputId": "f2c32ee8-149a-4480-f2e2-eb64b38897c5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    gradient_accumulation_steps=4,\n",
    "    fp16=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ImVPBTC7CS5l"
   },
   "outputs": [],
   "source": [
    "# set accuracy as metric\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "    return {\"accuracy\": accuracy}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f653sxGZCn5h"
   },
   "source": [
    "### Fine-tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 826
    },
    "id": "eZRJF-EhCpgt",
    "outputId": "41b7e4b8-0306-424d-9ed8-66e1425cbc8b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-16-0dfbf2ba7398>:19: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "[codecarbon INFO @ 02:32:24] [setup] RAM Tracking...\n",
      "[codecarbon INFO @ 02:32:24] [setup] CPU Tracking...\n",
      "[codecarbon WARNING @ 02:32:24] No CPU tracking mode found. Falling back on CPU constant mode. \n",
      " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
      "\n",
      "[codecarbon WARNING @ 02:32:25] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
      "[codecarbon INFO @ 02:32:25] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
      "[codecarbon INFO @ 02:32:25] [setup] GPU Tracking...\n",
      "[codecarbon INFO @ 02:32:25] Tracking Nvidia GPU via pynvml\n",
      "[codecarbon INFO @ 02:32:25] >>> Tracker's metadata:\n",
      "[codecarbon INFO @ 02:32:25]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
      "[codecarbon INFO @ 02:32:25]   Python version: 3.11.11\n",
      "[codecarbon INFO @ 02:32:25]   CodeCarbon version: 2.8.3\n",
      "[codecarbon INFO @ 02:32:25]   Available RAM : 12.675 GB\n",
      "[codecarbon INFO @ 02:32:25]   CPU count: 2\n",
      "[codecarbon INFO @ 02:32:25]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
      "[codecarbon INFO @ 02:32:25]   GPU count: 1\n",
      "[codecarbon INFO @ 02:32:25]   GPU model: 1 x Tesla T4\n",
      "[codecarbon INFO @ 02:32:26] Saving emissions data to file /content/results/emissions.csv\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjulianagc\u001b[0m (\u001b[33mjulianagc-ccole-\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20250130_023227-fh9aetrn</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/julianagc-ccole-/huggingface/runs/fh9aetrn' target=\"_blank\">./results</a></strong> to <a href='https://wandb.ai/julianagc-ccole-/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/julianagc-ccole-/huggingface' target=\"_blank\">https://wandb.ai/julianagc-ccole-/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/julianagc-ccole-/huggingface/runs/fh9aetrn' target=\"_blank\">https://wandb.ai/julianagc-ccole-/huggingface/runs/fh9aetrn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 02:32:44] Energy consumed for RAM : 0.000020 kWh. RAM Power : 4.7530388832092285 W\n",
      "[codecarbon INFO @ 02:32:44] Energy consumed for all CPUs : 0.000177 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 02:32:44] Energy consumed for all GPUs : 0.000217 kWh. Total GPU Power : 52.033674252100546 W\n",
      "[codecarbon INFO @ 02:32:44] 0.000414 kWh of electricity used since the beginning.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='974' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  4/974 00:29 < 4:02:18, 0.07 it/s, Epoch 0.00/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 02:32:59] Energy consumed for RAM : 0.000040 kWh. RAM Power : 4.7530388832092285 W\n",
      "[codecarbon INFO @ 02:32:59] Energy consumed for all CPUs : 0.000354 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 02:32:59] Energy consumed for all GPUs : 0.000479 kWh. Total GPU Power : 62.92325679153174 W\n",
      "[codecarbon INFO @ 02:32:59] 0.000873 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 02:33:14] Energy consumed for RAM : 0.000059 kWh. RAM Power : 4.7530388832092285 W\n",
      "[codecarbon INFO @ 02:33:14] Energy consumed for all CPUs : 0.000532 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 02:33:14] Energy consumed for all GPUs : 0.000739 kWh. Total GPU Power : 62.32345457570483 W\n",
      "[codecarbon INFO @ 02:33:14] 0.001330 kWh of electricity used since the beginning.\n"
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "val_losses = []\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "\n",
    "class MetricsLoggerCallback(TrainerCallback):\n",
    "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
    "      '''save train and validation losses for plotting'''\n",
    "      if logs is not None:\n",
    "        if \"loss\" in logs:\n",
    "          train_losses.append(logs[\"loss\"])\n",
    "        if \"eval_loss\" in logs:\n",
    "          val_losses.append(logs[\"eval_loss\"])\n",
    "        if \"eval_accuracy\" in logs:\n",
    "          val_accuracies.append(logs[\"eval_accuracy\"])\n",
    "        if \"accuracy\" in logs:\n",
    "          train_accuracies.append(logs[\"accuracy\"])\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[MetricsLoggerCallback],\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4K01mexJDiqI"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9VPiKqjy7CJZ"
   },
   "source": [
    "### Training curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dMery_AN6-1C"
   },
   "outputs": [],
   "source": [
    "# Plotting after training\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Plot Losses\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses, label=\"Training Loss\")\n",
    "plt.plot(val_losses, label=\"Validation Loss\")\n",
    "plt.title(\"Training and Validation Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "\n",
    "# Plot Accuracies\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_accuracies, label=\"Training Accuracy\")\n",
    "plt.plot(val_accuracies, label=\"Validation Accuracy\")\n",
    "plt.title(\"Training and Validation Accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YzgXDC1W_8Xx"
   },
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XnSxkr4-_zd3"
   },
   "outputs": [],
   "source": [
    "def evaluate_text(trainer, tokenized_datasets, dataset_name=\"quotaclimat/frugalaichallenge-text-train\"):\n",
    "    # Initialize CodeCarbon tracker\n",
    "    tracker = EmissionsTracker(project_name=\"text_classification_baseline\")\n",
    "\n",
    "    # Start tracking emissions\n",
    "    tracker.start()\n",
    "\n",
    "    ########################################################################\n",
    "    # ModernBERT inference\n",
    "    test_results = trainer.evaluate(tokenized_datasets[\"test\"])\n",
    "    print(f\"Test results: {test_results}\")\n",
    "    ########################################################################\n",
    "\n",
    "    # Stop tracking emissions\n",
    "    emissions = tracker.stop()\n",
    "\n",
    "    # Prepare results dictionary\n",
    "    results = {\n",
    "        \"accuracy\": float(test_results[\"eval_accuracy\"]),\n",
    "        \"energy_consumed_wh\": emissions.energy_consumed * 1000,\n",
    "        \"emissions_gco2eq\": emissions.emissions * 1000,\n",
    "        \"emissions_data\": emissions,\n",
    "        \"dataset_config\": {\n",
    "            \"dataset_name\": dataset_name,\n",
    "            \"test_size\": len(tokenized_datasets[\"test\"]),\n",
    "        }\n",
    "    }\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V1pVz7PjQfkS"
   },
   "outputs": [],
   "source": [
    "evaluation_results = evaluate_text(trainer, tokenized_datasets)\n",
    "print(evaluation_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7d41imd6xWHv"
   },
   "source": [
    "# Save the model and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NmP6g5duxYBI"
   },
   "outputs": [],
   "source": [
    "# After training is complete\n",
    "trainer.save_model(\"./results\")\n",
    "tokenizer.save_pretrained(\"./results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "npsuJDLhvqHs"
   },
   "source": [
    "# For the submission\n",
    "\n",
    "This is how to change the .py file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gHIcOW2pvro7"
   },
   "outputs": [],
   "source": [
    "from fastapi import APIRouter\n",
    "from datetime import datetime\n",
    "from datasets import load_dataset\n",
    "from sklearn.metrics import accuracy_score\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "from .utils.evaluation import TextEvaluationRequest\n",
    "from .utils.emissions import tracker, clean_emissions_data, get_space_info\n",
    "\n",
    "router = APIRouter()\n",
    "\n",
    "DESCRIPTION = \"Fine-tuned ModernBERT for Climate Disinformation Detection\"\n",
    "ROUTE = \"/text\"\n",
    "\n",
    "@router.post(ROUTE, tags=[\"Text Task\"],\n",
    "             description=DESCRIPTION)\n",
    "async def evaluate_text(request: TextEvaluationRequest):\n",
    "    # Get space info\n",
    "    username, space_url = get_space_info()\n",
    "\n",
    "    # Define the label mapping\n",
    "    LABEL_MAPPING = {\n",
    "        \"0_not_relevant\": 0,\n",
    "        \"1_not_happening\": 1,\n",
    "        \"2_not_human\": 2,\n",
    "        \"3_not_bad\": 3,\n",
    "        \"4_solutions_harmful_unnecessary\": 4,\n",
    "        \"5_science_unreliable\": 5,\n",
    "        \"6_proponents_biased\": 6,\n",
    "        \"7_fossil_fuels_needed\": 7\n",
    "    }\n",
    "\n",
    "    # Load the dataset\n",
    "    dataset = load_dataset(request.dataset_name)\n",
    "\n",
    "    # Start tracking emissions\n",
    "    tracker.start()\n",
    "    tracker.start_task(\"model_loading_and_inference\")\n",
    "\n",
    "    #--------------------------------------------------------------------------------------------\n",
    "    # MODEL LOADING AND INFERENCE CODE\n",
    "\n",
    "    # Load the fine-tuned model and tokenizer\n",
    "    model_path = \"path/to/your/saved/model\"  # Replace with your model path or HuggingFace model ID\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "    # Move model to GPU if available (T4 in this case)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    # Optimize model for inference\n",
    "    model.eval()\n",
    "\n",
    "    # Function to perform inference on a batch of texts\n",
    "    def predict_batch(texts):\n",
    "        inputs = tokenizer(texts, return_tensors=\"pt\", truncation=True, padding=True, max_length=512).to(device)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "        return torch.argmax(outputs.logits, dim=1).cpu().numpy()\n",
    "\n",
    "    # Perform inference on the entire dataset\n",
    "    batch_size = 32  # Adjust based on T4 memory constraints\n",
    "    all_predictions = []\n",
    "\n",
    "    for i in range(0, len(dataset['train']), batch_size):\n",
    "        batch_texts = dataset['train'][i:i+batch_size]['text']\n",
    "        batch_predictions = predict_batch(batch_texts)\n",
    "        all_predictions.extend(batch_predictions)\n",
    "\n",
    "    #--------------------------------------------------------------------------------------------\n",
    "    # MODEL INFERENCE ENDS HERE\n",
    "\n",
    "    # Stop tracking emissions\n",
    "    emissions_data = tracker.stop_task()\n",
    "\n",
    "    # Prepare results dictionary (without calculating accuracy)\n",
    "    results = {\n",
    "        \"username\": username,\n",
    "        \"space_url\": space_url,\n",
    "        \"submission_timestamp\": datetime.now().isoformat(),\n",
    "        \"model_description\": DESCRIPTION,\n",
    "        \"energy_consumed_wh\": emissions_data.energy_consumed * 1000,\n",
    "        \"emissions_gco2eq\": emissions_data.emissions * 1000,\n",
    "        \"emissions_data\": clean_emissions_data(emissions_data),\n",
    "        \"api_route\": ROUTE,\n",
    "        \"dataset_config\": {\n",
    "            \"dataset_name\": request.dataset_name\n",
    "        }\n",
    "    }\n",
    "\n",
    "    return results\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "01dd6d1a4053475da853c00463f02b35": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "04f3d68881fd42edb13138b3164e723e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "0aa0953a0f974d1c91c61df90ced095a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_17bc325db5c5429ba34d0c32a707b2ec",
       "IPY_MODEL_0d1c83c021c440af870a57809f3389e4",
       "IPY_MODEL_295f3aa9490f49a09c30bd26f2df741f"
      ],
      "layout": "IPY_MODEL_f23b7ffea8da4e7b8763cd9a32e8382b"
     }
    },
    "0d1c83c021c440af870a57809f3389e4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a2f7717732bc42a797cea85bab375e6a",
      "max": 3897,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e069534cc6f048cdb159b66167ee36d7",
      "value": 3897
     }
    },
    "0e93444e5a834ad78ccd6a1fdfa23b87": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "137e9dc3bc22481286d2b81ba0df6541": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_84bbb54169dc4fe8b0c45b6d0597b088",
       "IPY_MODEL_e7490ad417a64e8aaa969eeb989275b8",
       "IPY_MODEL_f69828d20aa14305b2814dca42eddb23"
      ],
      "layout": "IPY_MODEL_98615a5d1223470c9888676dd66f8ba7"
     }
    },
    "17bc325db5c5429ba34d0c32a707b2ec": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_52c46c1088cd4a7daf5bcc7e94e7d087",
      "placeholder": "​",
      "style": "IPY_MODEL_99cd9cd2ea4d4420b6b390303451e3dc",
      "value": "Map: 100%"
     }
    },
    "2052a53d024a42cf833cc9b0636176f2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "239ad12bdb0f433fb031fe2ce9679f3d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "295f3aa9490f49a09c30bd26f2df741f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_66837dd64b3b45f1a5c58c8f4242ea40",
      "placeholder": "​",
      "style": "IPY_MODEL_239ad12bdb0f433fb031fe2ce9679f3d",
      "value": " 3897/3897 [00:26&lt;00:00, 157.09 examples/s]"
     }
    },
    "3d5fb52ef5ac42b3b9a908ce692e09e6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "469c81a3f45c4803b4513eaee2693530": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_59cd769513bd4c118c04d7cfc264a4a3",
      "placeholder": "​",
      "style": "IPY_MODEL_d9a9cafcd88442c2a413d273b20dfe3e",
      "value": " 487/487 [00:01&lt;00:00, 310.01 examples/s]"
     }
    },
    "5196022684394923bfacd25d564d6fe4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_01dd6d1a4053475da853c00463f02b35",
      "placeholder": "​",
      "style": "IPY_MODEL_2052a53d024a42cf833cc9b0636176f2",
      "value": "Map: 100%"
     }
    },
    "52c46c1088cd4a7daf5bcc7e94e7d087": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "59cd769513bd4c118c04d7cfc264a4a3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "66837dd64b3b45f1a5c58c8f4242ea40": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6a50d6b1564a4ac8ad711893d1d0ba32": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7e178350d50b4955810ba3e2d9733f51": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7f5006b22c73431ca209452cbf70ac28": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "84bbb54169dc4fe8b0c45b6d0597b088": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_efba345573b54dca83bd88ce3c688358",
      "placeholder": "​",
      "style": "IPY_MODEL_3d5fb52ef5ac42b3b9a908ce692e09e6",
      "value": "Map: 100%"
     }
    },
    "884386a7232642b4be151749c69aefd1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5196022684394923bfacd25d564d6fe4",
       "IPY_MODEL_f3695012b5d5422fab1da2a8f7b2858b",
       "IPY_MODEL_469c81a3f45c4803b4513eaee2693530"
      ],
      "layout": "IPY_MODEL_0e93444e5a834ad78ccd6a1fdfa23b87"
     }
    },
    "98615a5d1223470c9888676dd66f8ba7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "99cd9cd2ea4d4420b6b390303451e3dc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a2f7717732bc42a797cea85bab375e6a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c179fefab74344368371b6457d36e7cf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d9a9cafcd88442c2a413d273b20dfe3e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e069534cc6f048cdb159b66167ee36d7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e7490ad417a64e8aaa969eeb989275b8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7f5006b22c73431ca209452cbf70ac28",
      "max": 488,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f1a00a892b534f37b6f38bcd0c262434",
      "value": 488
     }
    },
    "efba345573b54dca83bd88ce3c688358": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f1a00a892b534f37b6f38bcd0c262434": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f23b7ffea8da4e7b8763cd9a32e8382b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f3695012b5d5422fab1da2a8f7b2858b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c179fefab74344368371b6457d36e7cf",
      "max": 487,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_04f3d68881fd42edb13138b3164e723e",
      "value": 487
     }
    },
    "f69828d20aa14305b2814dca42eddb23": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7e178350d50b4955810ba3e2d9733f51",
      "placeholder": "​",
      "style": "IPY_MODEL_6a50d6b1564a4ac8ad711893d1d0ba32",
      "value": " 488/488 [00:01&lt;00:00, 302.90 examples/s]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
